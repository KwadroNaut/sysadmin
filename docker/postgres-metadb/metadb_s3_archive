#!/bin/sh
#
# This script runs at metadb PostgreSQL instance with following config:
#   archive_command = 'metadb_s3_archive "%p" "%f"'
# It ships WAL to S3 bucket https://ooni-data.s3.amazonaws.com/metadb/
# It expects AWS_* credentials as environment variables, awscli uses
# AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY.
# It updates Pushgateway with status, so it needs PUSHGATEWAY_CERT
# and PUSHGATEWAY_KEY env vars.
#

set -o errexit
set -o xtrace

pgtmp="base/pgsql_tmp" # CWD is PGDATA.
test -d "$pgtmp" -a -w "$pgtmp"

test $# -eq 2
walpath="$1"
walname="$2"
test -r "$walpath"
test -r "$PUSHGATEWAY_CERT" -a -r "$PUSHGATEWAY_KEY" # to submit status to Prometheus

success=0
kern=$(uname -s)
mach=$(uname -m)
pgver=$(cat PG_VERSION) # CWD is PGDATA.

# Something like https://ooni-data.s3.amazonaws.com/metadb/Linux-x86_64-9.6/wal/000000010000035E00000084
s3url="s3://ooni-data/metadb/${kern}-${mach}-${pgver}/wal/${walname}.xz"
rourl="https://ooni-data.s3.amazonaws.com/metadb/${kern}-${mach}-${pgver}/wal/${walname}.xz"

arch=$(mktemp --tmpdir="$pgtmp" ms3a.XXXXXXXXXX)

compress_begin=$(date +%s.%N)
xz -2 --stdout "$walpath" >"$arch"
compress_end=$(date +%s.%N)

size=$(stat --format="%s" "$arch")

upload_begin=$(date +%s.%N)
for try in 5 25 0; do
    if aws s3 cp --only-show-errors "$arch" "$s3url"; then
        break
    else
        sleep "$try"
    fi
done
upload_end=$(date +%s.%N)

rm "$arch"
compress_time=$(awk -v a="$compress_begin" -v b="$compress_end" 'END {print b - a}' /dev/null)
upload_time=$(awk -v a="$upload_begin" -v b="$upload_end" 'END {print b - a}' /dev/null)

# `aws s3 cp` has history of exit(0) despite failure, that's why `curl` double-check is here.
# That was observed in ooni/pipeline, that's still sometimes the case given following issues:
# https://github.com/aws/aws-cli/issues/3689 https://github.com/aws/aws-cli/issues/3977 etc.
# It's PostgreSQL's responsibility to restart this script in case of failure.
for try in 5 25 0; do
    len=$(curl --fail -sS --head "$rourl" | awk '(tolower($1) == "content-length:") {printf("%d", $2)}')
    if [ "$len" = "$size" ] && [ "$size" -gt 0 ]; then
        success=1
        break
    else
        sleep "$try"
    fi
done

# Yes, upload_time and compress_time do not perfectly fit into Prometheus data
# model and may benifit from counter-style metrics. But having statsd just for
# non-essential metrics of this script is an overkill.
for try in 5 25 0; do
    if curl --fail -sS -X PUT --data-binary @- --cert "$PUSHGATEWAY_CERT" --key "$PUSHGATEWAY_KEY" "https://prometheus.infra.ooni.io:9091/metrics/job/metadb_wal" <<EOF
# HELP metadb_wal_upload_seconds Time-to-upload last WAL segment.
# TYPE metadb_wal_upload_seconds gauge
metadb_wal_upload_seconds ${upload_time}
# HELP metadb_wal_compress_seconds Time-to-compress last WAL segment.
# TYPE metadb_wal_compress_seconds gauge
metadb_wal_compress_seconds ${compress_time}
# HELP metadb_wal_ship_time Timestamp of last WAL segment shipment.
# TYPE metadb_wal_ship_time gauge
metadb_wal_ship_time ${upload_end}
# HELP metadb_wal_ship_success Success of last WAL segment shipment.
# TYPE metadb_wal_ship_success gauge
metadb_wal_ship_success ${success}
EOF
    then
        break
    else
        sleep "$try"
    fi
done

if [ "$success" -eq 1 ]; then
    exit 0
else
    exit 1
fi
